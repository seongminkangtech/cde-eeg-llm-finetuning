"""
Hugging Face Transformers + TRL ê¸°ë°˜ íŒŒì¸íŠœë‹ íŠ¸ë ˆì´ë„ˆ
"""

from __future__ import annotations

import torch
import pandas as pd
from pathlib import Path
from tqdm import tqdm
from peft import LoraConfig
from transformers import TrainingArguments, EarlyStoppingCallback
from trl import SFTTrainer
from datasets import load_dataset
import mlflow
import mlflow.pytorch

from .config import ModelConfig, DataConfig, TrainerConfig
from .data import load_and_prepare_datasets
from .modeling import (
    maybe_install_flash_attn,
    build_quant_config,
    load_model_and_tokenizer,
)


def cleanup_memory():
    """ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜ (GPU/CPU ëª¨ë‘ ì ìš©)"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    import gc
    gc.collect()


def predict_label(pred):
    """
    ì˜ˆì¸¡ëœ ë ˆì´ë¸” ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ ë ˆì´ë¸”ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        pred (torch.Tensor): ì˜ˆì¸¡ëœ ë ˆì´ë¸” ì¸ë±ìŠ¤.
    
    Returns:
        str: ì‹¤ì œ ë ˆì´ë¸”.
    """
    # ìƒìˆ˜ ì •ì˜
    LABELS = ['Normal', 'Abnormal(Nonspecific)', 'Abnormal(Interictal)', 'Abnormal(Ictal)']
    return LABELS[int(pred[0])]


def test_model(model, tokenizer, text):
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        model: ì˜ˆì¸¡ì— ì‚¬ìš©í•  ëª¨ë¸.
        tokenizer: í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì§•í•˜ëŠ” ë° ì‚¬ìš©í•  í† í¬ë‚˜ì´ì €.
        text (str): ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸.
    
    Returns:
        torch.Tensor: ì˜ˆì¸¡ëœ ë ˆì´ë¸” ì¸ë±ìŠ¤.
    """
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    return predictions


def evaluate_model_on_test_data(eval_df, model, tokenizer, text_field: str):
    """
    ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„ì˜ ê° í–‰ì— ëŒ€í•´ ëª¨ë¸ì„ í‰ê°€í•˜ê³  ì˜ˆì¸¡ ë ˆì´ë¸”ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    ê° ë°˜ë³µë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        eval_df (pd.DataFrame): í‰ê°€í•  ë°ì´í„°í”„ë ˆì„.
        model: í‰ê°€ì— ì‚¬ìš©í•  ëª¨ë¸.
        tokenizer: í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì§•í•˜ëŠ” ë° ì‚¬ìš©í•  í† í¬ë‚˜ì´ì €.
        text_field (str): í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì´ë¦„.
    
    Returns:
        pd.DataFrame: ì˜ˆì¸¡ ë ˆì´ë¸”ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„.
    """
    print("í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤...")
    
    for idx, row in tqdm(eval_df.iterrows(), total=eval_df.shape[0], desc="Evaluating"):
        try:
            pred = test_model(model, tokenizer, row[text_field])
            eval_df.at[idx, 'Pred'] = predict_label(pred)
        except Exception as e:
            print(f"[{idx}] ì˜ˆì™¸ ë°œìƒ: {e}")
            eval_df.at[idx, 'Pred'] = None
        # ê° rowë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬
        cleanup_memory()
    
    return eval_df


def save_test_results(eval_df, output_dir: str, model_name: str, raw_label_field: str):
    """
    í‰ê°€ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        eval_df (pd.DataFrame): ì €ì¥í•  í‰ê°€ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„.
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬.
        model_name (str): ëª¨ë¸ ì´ë¦„.
        raw_label_field (str): ì‹¤ì œ ë ˆì´ë¸” ì»¬ëŸ¼ëª….
    
    Returns:
        float: í…ŒìŠ¤íŠ¸ ì •í™•ë„
    """
    output_path = Path(output_dir) / "test_results"
    output_path.mkdir(exist_ok=True)
    
    # ì •í™•ë„ ê³„ì‚°
    if 'Pred' in eval_df.columns and raw_label_field in eval_df.columns:
        correct = (eval_df['Pred'] == eval_df[raw_label_field]).sum()
        total = len(eval_df)
        accuracy = correct / total if total > 0 else 0
        
        print(f"\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
        print(f"ì „ì²´ ìƒ˜í”Œ ìˆ˜: {total}")
        print(f"ì •í™•ë„: {accuracy:.4f} ({correct}/{total})")
        
        # MLflowì— ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metric("test_accuracy", accuracy)
        mlflow.log_metric("test_total_samples", total)
        mlflow.log_metric("test_correct_predictions", correct)
        
        # ìƒì„¸í•œ ë¶„ë¥˜ ë¦¬í¬íŠ¸
        try:
            from sklearn.metrics import classification_report, confusion_matrix
            report = classification_report(
                eval_df[raw_label_field], 
                eval_df['Pred'], 
                target_names=['Normal', 'Abnormal(Nonspecific)', 'Abnormal(Interictal)', 'Abnormal(Ictal)'],
                output_dict=True
            )
            
            # ê° í´ë˜ìŠ¤ë³„ ì •í™•ë„ ë¡œê¹…
            for class_name, metrics in report.items():
                if isinstance(metrics, dict) and 'precision' in metrics:
                    mlflow.log_metric(f"test_{class_name}_precision", metrics['precision'])
                    mlflow.log_metric(f"test_{class_name}_recall", metrics['recall'])
                    mlflow.log_metric(f"test_{class_name}_f1", metrics['f1-score'])
            
            print(f"\nìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\n{classification_report(eval_df[raw_label_field], eval_df['Pred'], target_names=['Normal', 'Abnormal(Nonspecific)', 'Abnormal(Interictal)', 'Abnormal(Ictal)'])}")
            
            # í˜¼ë™ í–‰ë ¬ ë¡œê¹…
            cm = confusion_matrix(eval_df[raw_label_field], eval_df['Pred'], labels=['Normal', 'Abnormal(Nonspecific)', 'Abnormal(Interictal)', 'Abnormal(Ictal)'])
            cm_file = output_path / "confusion_matrix.txt"
            with open(cm_file, 'w') as f:
                f.write(str(cm))
            mlflow.log_artifact(str(cm_file), "confusion_matrix")
            
        except Exception as e:
            print(f"ë¶„ë¥˜ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ê²°ê³¼ ì €ì¥
    result_file = output_path / f"{model_name}_test_results.csv"
    eval_df.to_csv(result_file, index=False)
    
    # MLflowì— ê²°ê³¼ íŒŒì¼ ì•„í‹°íŒ©íŠ¸ë¡œ ë¡œê¹…
    mlflow.log_artifact(str(result_file), "test_results")
    
    print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ {result_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return accuracy


def build_lora_config_for_seq_cls() -> LoraConfig:
    """ë¶„ë¥˜ íƒœìŠ¤í¬ìš© ê¸°ë³¸ LoRA ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤."""

    return LoraConfig(
        lora_alpha=3,
        lora_dropout=0.1,
        r=4,
        bias="none",
        task_type="SEQ_CLS",
    )


def run_hf_training(
    model_conf: ModelConfig, 
    data_conf: DataConfig, 
    trainer_conf: TrainerConfig,
    mlflow_run=None
) -> None:
    """HF/TRL ì¡°í•©ìœ¼ë¡œ íŒŒì¸íŠœë‹ì„ ìˆ˜í–‰í•˜ê³  í•™ìŠµ ì™„ë£Œ í›„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€í•©ë‹ˆë‹¤."""

    # flash-attn ì—¬ë¶€ ë° dtype ê²°ì •
    _, torch_dtype = maybe_install_flash_attn()

    # ì–‘ìí™” ì„¤ì •
    quant_config = build_quant_config(model_conf.load_in_4bit, torch_dtype)

    # ëª¨ë¸/í† í¬ë‚˜ì´ì €
    model, tokenizer = load_model_and_tokenizer(
        model_conf.model_id, model_conf.model_dict, num_labels=model_conf.num_labels, quant_config=quant_config
    )

    # ë°ì´í„° ë¡œë“œ/ì „ì²˜ë¦¬
    train_dataset, eval_dataset = load_and_prepare_datasets(
        str(data_conf.train_csv_path),
        str(data_conf.eval_csv_path),
        tokenizer,
        text_field=data_conf.text_field,
        raw_label_field=data_conf.raw_label_field,
        max_length=data_conf.max_seq_length,
    )

    # LoRA ì„¤ì •
    peft_params = build_lora_config_for_seq_cls()

    # í•™ìŠµ ì¸ì
    training_args = TrainingArguments(
        output_dir=str(trainer_conf.output_dir),
        num_train_epochs=trainer_conf.num_train_epochs,
        per_device_train_batch_size=trainer_conf.per_device_train_batch_size,
        per_device_eval_batch_size=trainer_conf.per_device_eval_batch_size,
        gradient_accumulation_steps=trainer_conf.gradient_accumulation_steps,
        learning_rate=trainer_conf.learning_rate,
        weight_decay=trainer_conf.weight_decay,
        fp16=trainer_conf.fp16,
        bf16=trainer_conf.bf16,
        optim=trainer_conf.optim,
        save_steps=trainer_conf.save_steps,
        logging_steps=trainer_conf.logging_steps,
        max_grad_norm=trainer_conf.max_grad_norm,
        max_steps=trainer_conf.max_steps,
        warmup_ratio=trainer_conf.warmup_ratio,
        group_by_length=trainer_conf.group_by_length,
        lr_scheduler_type=trainer_conf.lr_scheduler_type,
        report_to="none",  # MLflowì™€ ì¶©ëŒ ë°©ì§€
        gradient_checkpointing=trainer_conf.gradient_checkpointing,
        evaluation_strategy=trainer_conf.eval_strategy,
        eval_steps=trainer_conf.eval_steps,
        load_best_model_at_end=trainer_conf.load_best_model_at_end,
    )

    # íŠ¸ë ˆì´ë„ˆ êµ¬ì„± ë° í•™ìŠµ
    trainer = SFTTrainer(
        model=model,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        peft_config=peft_params,
        args=training_args,
        dataset_text_field=data_conf.text_field,
        packing=True,
        max_seq_length=data_conf.max_seq_length,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=10)],
    )

    print("ğŸš€ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # í•™ìŠµ ì¤‘ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì„ ìœ„í•œ ì½œë°±
    class MLflowCallback:
        def __init__(self):
            self.step = 0
            
        def on_log(self, args, state, control, logs=None, **kwargs):
            if logs:
                for key, value in logs.items():
                    if isinstance(value, (int, float)):
                        mlflow.log_metric(key, value, step=self.step)
                self.step += 1
    
    # MLflow ì½œë°± ì¶”ê°€
    trainer.add_callback(MLflowCallback())
    
    # í•™ìŠµ ì‹¤í–‰
    train_result = trainer.train()
    
    print("âœ… í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # í•™ìŠµ ê²°ê³¼ MLflowì— ë¡œê¹…
    if train_result:
        mlflow.log_metric("train_loss", train_result.training_loss)
        mlflow.log_metric("train_runtime", train_result.metrics.get("train_runtime", 0))
        mlflow.log_metric("train_samples_per_second", train_result.metrics.get("train_samples_per_second", 0))
    
    # ëª¨ë¸ ì €ì¥
    model_save_path = Path(trainer_conf.output_dir) / "final_model"
    trainer.save_model(str(model_save_path))
    tokenizer.save_pretrained(str(model_save_path))
    
    # MLflowì— ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë¡œê¹…
    mlflow.log_artifact(str(model_save_path), "model")
    
    # í•™ìŠµ ì™„ë£Œ í›„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€ (data_configì—ì„œ ì§ì ‘ ì‚¬ìš©)
    if data_conf.test_csv_path and data_conf.test_csv_path.exists():
        print("\nğŸ§ª í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í‰ê°€í•©ë‹ˆë‹¤...")
        
        try:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
            test_df = pd.read_csv(data_conf.test_csv_path)
            
            # ì»¬ëŸ¼ëª… í™•ì¸ ë° í†µì¼
            if data_conf.text_field not in test_df.columns:
                print(f"ê²½ê³ : '{data_conf.text_field}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {test_df.columns.tolist()}")
                return
            
            # ë ˆì´ë¸” ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸ (data_configì˜ raw_label_field ì‚¬ìš©)
            if data_conf.raw_label_field not in test_df.columns:
                print(f"ê²½ê³ : '{data_conf.raw_label_field}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return
            
            # ëª¨ë¸ í‰ê°€
            test_df_with_predictions = evaluate_model_on_test_data(
                test_df, model, tokenizer, data_conf.text_field
            )
            
            # ê²°ê³¼ ì €ì¥
            model_name = Path(trainer_conf.output_dir).name
            test_accuracy = save_test_results(test_df_with_predictions, trainer_conf.output_dir, model_name, data_conf.raw_label_field)
            
            # ìµœì¢… ì„±ëŠ¥ ìš”ì•½
            print(f"\nğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
            
        except Exception as e:
            print(f"í…ŒìŠ¤íŠ¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            cleanup_memory()
    
    elif data_conf.test_csv_path:
        print(f"ê²½ê³ : í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_conf.test_csv_path}")
    
    else:
        print("í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œê°€ ì œê³µë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    print("ï¿½ï¿½ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

