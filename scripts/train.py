#!/usr/bin/env python3
"""
CDE-EEG-LLM íŒŒì¸íŠœë‹ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/train.py --method hf          # Hugging Face ê¸°ë°˜
    python scripts/train.py --method unsloth     # Unsloth ê¸°ë°˜
"""

from dotenv import load_dotenv
load_dotenv()

import argparse
import sys
import os
from pathlib import Path
import mlflow
import mlflow.pytorch
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.training.config import ModelConfig, DataConfig, TrainerConfig, MLflowConfig
from src.training.trainer_hf import run_hf_training
from src.training.trainer_unsloth import run_unsloth_training, run_unsloth_testing, run_unsloth_train_testing

def force_environment_variables():
    """í™˜ê²½ ë³€ìˆ˜ë¥¼ ê°•ì œë¡œ ì„¤ì •í•©ë‹ˆë‹¤."""
    
    project_root = Path(__file__).parent.parent
    cache_dir = project_root / "cache"
    cache_dir.mkdir(exist_ok=True)
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ ìë™ ìƒì„±
    (cache_dir / "unsloth").mkdir(exist_ok=True)
    (cache_dir / "huggingface").mkdir(exist_ok=True)
    (cache_dir / "transformers").mkdir(exist_ok=True)
    (cache_dir / "datasets").mkdir(exist_ok=True)
    (cache_dir / "unsloth" / "compiled").mkdir(parents=True, exist_ok=True)
    (cache_dir / "unsloth" / "models").mkdir(parents=True, exist_ok=True)
    
    # í™˜ê²½ ë³€ìˆ˜ ê°•ì œ ì„¤ì •
    os.environ["UNSLOTH_CACHE_DIR"] = str(cache_dir / "unsloth")
    os.environ["HF_HOME"] = str(cache_dir / "huggingface")
    os.environ["TRANSFORMERS_CACHE"] = str(cache_dir / "transformers")
    os.environ["HF_DATASETS_CACHE"] = str(cache_dir / "datasets")
    os.environ["UNSLOTH_COMPILE_CACHE_DIR"] = str(cache_dir / "unsloth" / "compiled")
    os.environ["UNSLOTH_MODEL_CACHE_DIR"] = str(cache_dir / "unsloth" / "models")
    
    print(" í™˜ê²½ ë³€ìˆ˜ ê°•ì œ ì„¤ì • ì™„ë£Œ:")
    for key, value in os.environ.items():
        if "CACHE" in key or "HF_" in key or "UNSLOTH" in key:
            print(f"   {key}: {value}")

def create_default_configs(method:str) -> tuple[ModelConfig, DataConfig, TrainerConfig, MLflowConfig]:
    """ê¸°ë³¸ ì„¤ì •ê°’ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # ëª¨ë¸ ì„¤ì •
    model_config = ModelConfig(
        model_id="gpt-oss-20b",
        model_dict={
            'Llama-3.1-8B': 'meta-llama/Llama-3.1-8B',
            'Llama-3.1-8B-Instruct': 'meta-llama/Llama-3.1-8B-Instruct',
            'Llama-3.1-70B': 'meta-llama/Llama-3.1-70B',
            'Llama-3.2-3B': 'meta-llama/Llama-3.2-3B',
            'Mistral-7B-Instruct-v0.3': 'mistralai/Mistral-7B-Instruct-v0.3',
            'falcon-7B': 'tiiuae/falcon-7b',
            'falcon-11B': 'tiiuae/falcon-11B',
            't5-small': 'google-t5/t5-small',
            'gpt-oss-20b': 'unsloth/gpt-oss-20b',
        },
        num_labels=4,
        use_qlora=True,
        load_in_4bit=True,
        use_flash_attn_if_available=True,
    )
    
    # ë°ì´í„° ì„¤ì •
    data_config = DataConfig(
        train_csv_path=Path("data/250723_train.csv"),
        eval_csv_path=Path("data/250723_eval.csv"),
        test_csv_path=Path("data/250723_test.csv"),
        text_field="EMR",
        raw_label_field="True",
        max_seq_length=1024,
    )
    
    # MLflow ì„¤ì •
    # DB íŒŒì¼ì„ mlruns ë””ë ‰í† ë¦¬ ë‚´ë¶€ì— ìœ„ì¹˜í•˜ë„ë¡ ê²½ë¡œ ì§€ì •
    mlflow_config = MLflowConfig(
        experiment_name="cde-eeg-llm-finetuning",
        tracking_uri="mlruns",  # íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œë¡œ MLflow íŠ¸ë˜í‚¹
        artifact_location="mlruns",
        log_artifacts=True,
        log_models=True,
        log_hyperparams=True,
        log_metrics=True,
    )
    
    # í•™ìŠµ ì„¤ì •
    trainer_config = TrainerConfig(
        output_dir=Path(f"output/{model_config.model_id}_{method}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"),
        num_train_epochs=5,
        per_device_train_batch_size=2,
        per_device_eval_batch_size=2,
        gradient_accumulation_steps=8,
        learning_rate=1e-4,
        weight_decay=1e-4,
        fp16=False,
        bf16=True,
        optim="paged_adamw_8bit",
        save_steps=25,
        logging_steps=10,
        max_grad_norm=1.0,
        max_steps=-1,
        warmup_ratio=0.1,
        group_by_length=True,
        lr_scheduler_type="cosine",
        report_to="mlflow",
        gradient_checkpointing=True,
    )
    
    return model_config, data_config, trainer_config, mlflow_config


def setup_mlflow_experiment(mlflow_config: MLflowConfig, model_id: str, method: str):
    """MLflow ì‹¤í—˜ì„ ì„¤ì •í•˜ê³  ì‹œì‘í•©ë‹ˆë‹¤."""
    
    # MLflow ì„¤ì •
    mlflow.set_tracking_uri(mlflow_config.tracking_uri)
    
    # ì‹¤í—˜ ì´ë¦„ ì„¤ì •
    experiment_name = f"{mlflow_config.experiment_name}_{method.upper()}"
    mlflow.set_experiment(experiment_name)
    
    # ì‹¤í—˜ ì‹œì‘
    with mlflow.start_run(run_name=f"{model_id}_{method}_{datetime.now().strftime('%Y%m%d_%H%M%S')}") as run:
        print(f"ğŸ”¬ MLflow ì‹¤í—˜ ì‹œì‘: {experiment_name}")
        print(f"ğŸ“Š Run ID: {run.info.run_id}")
        print(f"ğŸ”— MLflow UI: mlflow ui --backend-store-uri {mlflow_config.tracking_uri}")
        
        return run


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(description="CDE-EEG-LLM íŒŒì¸íŠœë‹")
    parser.add_argument(
        "--method",
        choices=["hf", "unsloth"],
        default="unsloth",
        help="íŒŒì¸íŠœë‹ ë°©ë²• ì„ íƒ (ê¸°ë³¸ê°’: unsloth)"
    )
    parser.add_argument(
        "--config",
        type=str,
        help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)"
    )
    
    args = parser.parse_args()
    
    # ğŸš¨ í™˜ê²½ ë³€ìˆ˜ë¥¼ ê°€ì¥ ë¨¼ì € ì„¤ì •
    force_environment_variables()

    # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
    model_config, data_config, trainer_config, mlflow_config = create_default_configs(args.method)
    
    print(f"ğŸš€ CDE-EEG-LLM íŒŒì¸íŠœë‹ ì‹œì‘")
    print(f"ğŸ“‹ ë°©ë²•: {args.method.upper()}")
    print(f"ğŸ§  ëª¨ë¸: {model_config.model_id}")
    print(f"ğŸ“Š í›ˆë ¨ ë°ì´í„°: {data_config.train_csv_path}")
    print(f"ğŸ“Š ê²€ì¦ ë°ì´í„°: {data_config.eval_csv_path}")
    print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°: {data_config.test_csv_path}")
    print(f"ğŸ’¾ ì¶œë ¥: {trainer_config.output_dir}")
    print(f"ğŸ”¬ MLflow ì‹¤í—˜: {mlflow_config.experiment_name}")
    print("-" * 50)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    trainer_config.output_dir.mkdir(parents=True, exist_ok=True)
    
    # MLflow ì‹¤í—˜ ì„¤ì •
    mlflow_run = setup_mlflow_experiment(mlflow_config, model_config.model_id, args.method)
    
    try:
        # MLflowì— í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params({
            "model_id": model_config.model_id,
            "method": args.method,
            "num_labels": model_config.num_labels,
            "use_qlora": model_config.use_qlora,
            "load_in_4bit": model_config.load_in_4bit,
            "max_seq_length": data_config.max_seq_length,
            "num_train_epochs": trainer_config.num_train_epochs,
            "learning_rate": trainer_config.learning_rate,
            "batch_size": trainer_config.per_device_train_batch_size,
            "gradient_accumulation_steps": trainer_config.gradient_accumulation_steps,
        })
        
        # ë°ì´í„°ì…‹ ì •ë³´ ë¡œê¹…
        mlflow.log_params({
            "train_data": str(data_config.train_csv_path),
            "eval_data": str(data_config.eval_csv_path),
            "test_data": str(data_config.test_csv_path),
            "text_field": data_config.text_field,
            "label_field": data_config.raw_label_field,
        })
        
        # ìºì‹œ ì •ë³´ ë¡œê¹…
        mlflow.log_params({
            "unsloth_cache_dir": os.environ.get('UNSLOTH_CACHE_DIR'),
            "hf_home": os.environ.get('HF_HOME'),
            "transformers_cache": os.environ.get('TRANSFORMERS_CACHE'),
            "datasets_cache": os.environ.get('HF_DATASETS_CACHE'),
        })
        
        if args.method == "hf":
            print("ğŸ”„ Hugging Face ê¸°ë°˜ íŒŒì¸íŠœë‹ ì‹œì‘...")
            run_hf_training(model_config, data_config, trainer_config, mlflow_run)
        elif args.method == "unsloth":
            print("âš¡ Unsloth ê¸°ë°˜ íŒŒì¸íŠœë‹ ì‹œì‘...")
            run_unsloth_train_testing(model_config, data_config, trainer_config, mlflow_run)
        
        print("âœ… íŒŒì¸íŠœë‹ ì™„ë£Œ!")
        
        # ìµœì¢… ëª¨ë¸ ë“±ë¡
        if mlflow_config.log_models:
            model_path = trainer_config.output_dir / "final_model"
            if model_path.exists():
                mlflow.pytorch.log_model(
                    pytorch_model=model_path,
                    artifact_path="model",
                    registered_model_name=f"cde-eeg-llm-{args.method}-{model_config.model_id}"
                )
                print(f"ğŸ·ï¸ ëª¨ë¸ì´ MLflowì— ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤: cde-eeg-llm-{args.method}-{model_config.model_id}")
        # ì„±ê³µ ìƒíƒœ ë¡œê¹…
        mlflow.log_param("status", "completed")

    except Exception as e:
        print(f"âŒ íŒŒì¸íŠœë‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        mlflow.log_param("status", "failed")
        mlflow.log_param("error", str(e))
        sys.exit(1)
    
    finally:
        print(f"ğŸ”¬ MLflow ì‹¤í—˜ ì™„ë£Œ: {mlflow_run.info.run_id}")


if __name__ == "__main__":
    main()

