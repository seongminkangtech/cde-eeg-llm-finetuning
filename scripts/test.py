#!/usr/bin/env python3
"""
CDE-EEG-LLM í…ŒìŠ¤íŠ¸ ì „ìš© ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/test.py --method unsloth --model_path output/gpt-oss-20b_unsloth_20250101_120000/unsloth_model
    python scripts/test.py --method unsloth --output_dir output/gpt-oss-20b_unsloth_20250101_120000
"""

from dotenv import load_dotenv
load_dotenv()

import argparse
import sys
import os
from pathlib import Path
import mlflow
import mlflow.pytorch
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.training.config import ModelConfig, DataConfig, TrainerConfig, MLflowConfig
from src.training.trainer_unsloth import run_unsloth_testing


def force_environment_variables():
    """í™˜ê²½ ë³€ìˆ˜ë¥¼ ê°•ì œë¡œ ì„¤ì •í•©ë‹ˆë‹¤."""
    
    project_root = Path(__file__).parent.parent
    cache_dir = project_root / "cache"
    cache_dir.mkdir(exist_ok=True)
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ ìë™ ìƒì„±
    (cache_dir / "unsloth").mkdir(exist_ok=True)
    (cache_dir / "huggingface").mkdir(exist_ok=True)
    (cache_dir / "transformers").mkdir(exist_ok=True)
    (cache_dir / "datasets").mkdir(exist_ok=True)
    (cache_dir / "unsloth" / "compiled").mkdir(parents=True, exist_ok=True)
    (cache_dir / "unsloth" / "models").mkdir(parents=True, exist_ok=True)
    
    # í™˜ê²½ ë³€ìˆ˜ ê°•ì œ ì„¤ì •
    os.environ["UNSLOTH_CACHE_DIR"] = str(cache_dir / "unsloth")
    os.environ["HF_HOME"] = str(cache_dir / "huggingface")
    os.environ["TRANSFORMERS_CACHE"] = str(cache_dir / "huggingface")
    os.environ["HF_DATASETS_CACHE"] = str(cache_dir / "datasets")
    os.environ["UNSLOTH_COMPILE_CACHE_DIR"] = str(cache_dir / "unsloth" / "compiled")
    os.environ["UNSLOTH_MODEL_CACHE_DIR"] = str(cache_dir / "unsloth" / "models")
    
    print("âœ… í™˜ê²½ ë³€ìˆ˜ ê°•ì œ ì„¤ì • ì™„ë£Œ:")
    for key, value in os.environ.items():
        if "CACHE" in key or "HF_" in key or "UNSLOTH" in key:
            print(f"   {key}: {value}")


def create_test_configs(method: str, model_path: Path = None, output_dir: Path = None) -> tuple[ModelConfig, DataConfig, TrainerConfig, MLflowConfig]:
    """í…ŒìŠ¤íŠ¸ìš© ì„¤ì •ê°’ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # ëª¨ë¸ ì„¤ì •
    model_config = ModelConfig(
        model_id="gpt-oss-20b",
        model_dict={
            'Llama-3.1-8B': 'meta-llama/Llama-3.1-8B',
            'Llama-3.1-8B-Instruct': 'meta-llama/Llama-3.1-8B-Instruct',
            'Llama-3.1-70B': 'meta-llama/Llama-3.1-70B',
            'Llama-3.2-3B': 'meta-llama/Llama-3.2-3B',
            'Mistral-7B-Instruct-v0.3': 'mistralai/Mistral-7B-Instruct-v0.3',
            'falcon-7B': 'tiiuae/falcon-7b',
            'falcon-11B': 'tiiuae/falcon-11B',
            't5-small': 'google-t5/t5-small',
            'gpt-oss-20b': 'unsloth/gpt-oss-20b',
        },
        num_labels=4,
        use_qlora=True,
        load_in_4bit=True,
        use_flash_attn_if_available=True,
    )
    
    # ë°ì´í„° ì„¤ì •
    data_config = DataConfig(
        train_csv_path=Path("data/250723_train.csv"),
        eval_csv_path=Path("data/250723_eval.csv"),
        test_csv_path=Path("data/250723_test.csv"),
        text_field="EMR",
        raw_label_field="True",
        max_seq_length=1024,
    )
    
    # MLflow ì„¤ì •
    mlflow_config = MLflowConfig(
        experiment_name="cde-eeg-llm-testing",
        tracking_uri="mlruns",
        artifact_location="mlruns",
        log_artifacts=True,
        log_models=True,
        log_hyperparams=True,
        log_metrics=True,
    )
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if output_dir is None:
        if model_path:
            # model_pathì—ì„œ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ output_dirë¡œ ì‚¬ìš©
            output_dir = model_path.parent
        else:
            # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬
            output_dir = Path(f"output/test_{method}_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    
    # í•™ìŠµ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ê°„ì†Œí™”)
    trainer_config = TrainerConfig(
        output_dir=output_dir,
        num_train_epochs=0,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        per_device_train_batch_size=1,
        per_device_eval_batch_size=1,
        gradient_accumulation_steps=1,
        learning_rate=0,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        weight_decay=0,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        fp16=False,
        bf16=True,
        optim="adamw_8bit",
        save_steps=0,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        logging_steps=1,
        max_grad_norm=0.3,
        max_steps=0,  # í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        warmup_ratio=0,
        group_by_length=True,
        lr_scheduler_type="constant",
        report_to="mlflow",
        gradient_checkpointing=True,
    )
    
    return model_config, data_config, trainer_config, mlflow_config


def setup_mlflow_experiment(mlflow_config: MLflowConfig, method: str, model_path: Path = None):
    """MLflow ì‹¤í—˜ì„ ì„¤ì •í•˜ê³  ì‹œì‘í•©ë‹ˆë‹¤."""
    
    # MLflow ì„¤ì •
    mlflow.set_tracking_uri(mlflow_config.tracking_uri)
    
    # ì‹¤í—˜ ì´ë¦„ ì„¤ì •
    experiment_name = f"{mlflow_config.experiment_name}_{method.upper()}"
    mlflow.set_experiment(experiment_name)
    
    # run_name ìƒì„±
    if model_path:
        model_name = model_path.parent.name
    else:
        model_name = "unknown_model"
    
    run_name = f"test_{model_name}_{method}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # ì‹¤í—˜ ì‹œì‘
    with mlflow.start_run(run_name=run_name) as run:
        print(f"ğŸ”¬ MLflow í…ŒìŠ¤íŠ¸ ì‹¤í—˜ ì‹œì‘: {experiment_name}")
        print(f"ğŸ“Š Run ID: {run.info.run_id}")
        print(f"ğŸ”— MLflow UI: mlflow ui --backend-store-uri {mlflow_config.tracking_uri}")
        
        return run


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(description="CDE-EEG-LLM í…ŒìŠ¤íŠ¸")
    parser.add_argument(
        "--method",
        choices=["unsloth"],
        default="unsloth",
        help="í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ë°©ë²• ì„ íƒ (ê¸°ë³¸ê°’: unsloth)"
    )
    parser.add_argument(
        "--model_path",
        type=str,
        help="í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ê²½ë¡œ (ì˜ˆ: output/gpt-oss-20b_unsloth_20250101_120000/unsloth_model)"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        help="ê²°ê³¼ë¥¼ ì €ì¥í•  ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì„ íƒì‚¬í•­)"
    )
    parser.add_argument(
        "--config",
        type=str,
        help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)"
    )
    
    args = parser.parse_args()
    
    # ğŸš¨ í™˜ê²½ ë³€ìˆ˜ë¥¼ ê°€ì¥ ë¨¼ì € ì„¤ì •
    force_environment_variables()

    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    model_path = None
    if args.model_path:
        model_path = Path(args.model_path)
        if not model_path.exists():
            print(f"âŒ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            sys.exit(1)
        print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ: {model_path}")
    else:
        print("âš ï¸ --model_pathê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    output_dir = None
    if args.output_dir:
        output_dir = Path(args.output_dir)
    
    # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
    model_config, data_config, trainer_config, mlflow_config = create_test_configs(
        args.method, model_path, output_dir
    )
    
    print(f"ğŸš€ CDE-EEG-LLM í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“‹ ë°©ë²•: {args.method.upper()}")
    print(f"ğŸ§  ëª¨ë¸: {model_config.model_id}")
    print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°: {data_config.test_csv_path}")
    print(f"ğŸ’¾ ì¶œë ¥: {trainer_config.output_dir}")
    print(f"ğŸ“Š MLflow ì‹¤í—˜: {mlflow_config.experiment_name}")
    print("-" * 50)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    trainer_config.output_dir.mkdir(parents=True, exist_ok=True)
    
    # MLflow ì‹¤í—˜ ì„¤ì •
    mlflow_run = setup_mlflow_experiment(mlflow_config, args.method, model_path)
    
    try:
        # MLflowì— í…ŒìŠ¤íŠ¸ ì •ë³´ ë¡œê¹…
        mlflow.log_params({
            "test_type": "model_evaluation",
            "method": args.method,
            "model_path": str(model_path) if model_path else "default",
            "num_labels": model_config.num_labels,
            "use_qlora": model_config.use_qlora,
            "load_in_4bit": model_config.load_in_4bit,
            "max_seq_length": data_config.max_seq_length,
        })
        
        # ë°ì´í„°ì…‹ ì •ë³´ ë¡œê¹…
        mlflow.log_params({
            "test_data": str(data_config.test_csv_path),
            "text_field": data_config.text_field,
            "label_field": data_config.raw_label_field,
        })
        
        # ìºì‹œ ì •ë³´ ë¡œê¹…
        mlflow.log_params({
            "unsloth_cache_dir": os.environ.get('UNSLOTH_CACHE_DIR'),
            "hf_home": os.environ.get('HF_HOME'),
            "transformers_cache": os.environ.get('TRANSFORMERS_CACHE'),
            "datasets_cache": os.environ.get('HF_DATASETS_CACHE'),
        })
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        if args.method == "unsloth":
            print("âš¡ Unsloth ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
            test_accuracy = run_unsloth_testing(
                model_config, 
                data_config, 
                trainer_config, 
                model_path, 
                mlflow_run
            )
            print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ì •í™•ë„: {test_accuracy:.4f}")
        
        # ì„±ê³µ ìƒíƒœ ë¡œê¹…
        mlflow.log_param("status", "completed")
        mlflow.log_metric("final_test_accuracy", test_accuracy)

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        mlflow.log_param("status", "failed")
        mlflow.log_param("error", str(e))
        sys.exit(1)
    
    finally:
        print(f"ğŸ”¬ MLflow í…ŒìŠ¤íŠ¸ ì‹¤í—˜ ì™„ë£Œ: {mlflow_run.info.run_id}")


if __name__ == "__main__":
    main()